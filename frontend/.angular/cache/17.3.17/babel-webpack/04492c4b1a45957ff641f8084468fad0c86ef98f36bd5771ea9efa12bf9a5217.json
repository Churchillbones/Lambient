{"ast":null,"code":"import _asyncToGenerator from \"C:/Users/lamb0/OneDrive/Desktop/Allan/New folder/Ambient-Transcription-with-GPT-Note-Creation-/frontend/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\nimport { __decorate } from \"tslib\";\nimport { Component } from '@angular/core';\nimport { interval } from 'rxjs';\nlet AppComponent = class AppComponent {\n  constructor(http, transcriptionService, cdr) {\n    this.http = http;\n    this.transcriptionService = transcriptionService;\n    this.cdr = cdr;\n    // UI State\n    this.activeTab = 'record';\n    this.sidebarCollapsed = false;\n    this.currentStep = 0;\n    this.showResults = false;\n    // Template options with actual prompts\n    this.defaultTemplates = [{\n      value: 'SOAP',\n      label: 'SOAP Note',\n      description: 'Standard Subjective, Objective, Assessment, Plan',\n      prompt: `Please format the following medical transcription into a SOAP note format:\n\n**SOAP NOTE**\n\n**SUBJECTIVE:**\n- Chief complaint and history of present illness\n- Review of systems as documented\n- Past medical/surgical/family/social history as mentioned\n\n**OBJECTIVE:**\n- Vital signs and physical examination findings\n- Laboratory and diagnostic results as discussed\n- Clinical observations\n\n**ASSESSMENT:**\n- Primary diagnosis/diagnoses\n- Secondary diagnoses if applicable\n- Clinical impression based on findings\n\n**PLAN:**\n- Treatment recommendations\n- Medications prescribed or adjusted\n- Follow-up instructions\n- Patient education provided\n\nPlease ensure all medical terminology is accurate and properly formatted. Include only information explicitly mentioned in the transcription.`\n    }, {\n      value: 'PrimaryCare',\n      label: 'Primary Care Visit',\n      description: 'Comprehensive primary care documentation',\n      prompt: `Please format the following medical transcription into a comprehensive primary care visit note:\n\n**PRIMARY CARE VISIT NOTE**\n\n**CHIEF COMPLAINT:**\n[Main reason for visit]\n\n**HISTORY OF PRESENT ILLNESS:**\n[Detailed description of current condition]\n\n**REVIEW OF SYSTEMS:**\n[Systems reviewed during visit]\n\n**PAST MEDICAL HISTORY:**\n[Relevant past medical conditions]\n\n**MEDICATIONS:**\n[Current medications discussed]\n\n**PHYSICAL EXAMINATION:**\n[Physical exam findings]\n\n**ASSESSMENT AND PLAN:**\n[For each problem identified:]\n- Problem: [Diagnosis/Issue]\n- Assessment: [Clinical thinking]\n- Plan: [Specific actions/treatments]\n\n**PATIENT EDUCATION:**\n[Education provided to patient]\n\n**FOLLOW-UP:**\n[Next steps and follow-up instructions]`\n    }, {\n      value: 'Emergency Department',\n      label: 'Emergency Department',\n      description: 'ED visit documentation',\n      prompt: `Please format the following medical transcription into an Emergency Department note:\n\n**EMERGENCY DEPARTMENT NOTE**\n\n**CHIEF COMPLAINT:**\n[Primary reason for ED visit]\n\n**HISTORY OF PRESENT ILLNESS:**\n[Timeline and details of current condition]\n\n**PAST MEDICAL HISTORY:**\n[Relevant medical history]\n\n**MEDICATIONS:**\n[Current medications]\n\n**ALLERGIES:**\n[Known allergies]\n\n**VITAL SIGNS:**\n[Vital signs on arrival and during stay]\n\n**PHYSICAL EXAMINATION:**\n[Systematic physical exam findings]\n\n**DIAGNOSTIC STUDIES:**\n[Labs, imaging, other tests performed]\n\n**EMERGENCY DEPARTMENT COURSE:**\n[Treatment provided in ED]\n\n**MEDICAL DECISION MAKING:**\n[Clinical reasoning and decision process]\n\n**DISPOSITION:**\n[Discharge vs admission decision and rationale]\n\n**DISCHARGE INSTRUCTIONS:**\n[Patient instructions and follow-up care]`\n    }];\n    this.customTemplates = [];\n    this.templateOptions = [];\n    // Template management\n    this.showTemplateManager = false;\n    this.selectedTemplateForEditing = null;\n    this.editingTemplateName = '';\n    this.editingTemplatePrompt = '';\n    this.isCreatingNewTemplate = false;\n    // Local model options\n    this.localModelOptions = [{\n      value: 'gemma3-4b',\n      label: 'Gemma 3 4B',\n      description: 'Fast, efficient model good for medical tasks (~4GB)'\n    }, {\n      value: 'deepseek-r1-14b',\n      label: 'DeepSeek R1 14B',\n      description: 'Large, powerful model for complex medical documentation (~14GB)'\n    }, {\n      value: 'llama3',\n      label: 'Llama 3',\n      description: 'Meta\\'s general purpose model'\n    }, {\n      value: 'phi4',\n      label: 'Phi 4',\n      description: 'Microsoft\\'s compact model'\n    }];\n    // Configuration\n    this.config = {\n      azureApiKey: '',\n      azureEndpoint: 'https://your-resource.openai.azure.com/',\n      noteModel: 'azure',\n      localModel: 'gemma3-4b',\n      asrEngine: 'vosk',\n      voskModel: 'vosk-model-en-us-0.22',\n      whisperModel: 'tiny',\n      encryptRecordings: true,\n      selectedTemplate: 'SOAP'\n    };\n    // Consent\n    this.consentDocumented = false;\n    this.patientName = '';\n    this.consentDate = new Date();\n    // Recording\n    this.recordingMode = 'traditional';\n    this.isRecording = false;\n    this.recordingTime = '00:00';\n    this.recordingStartTime = 0;\n    this.audioChunks = [];\n    // Transcription\n    this.finalTranscriptionText = '';\n    this.partialTranscriptionText = '';\n    this.lowConfidenceWords = [];\n    // Results\n    this.rawTranscription = '';\n    this.cleanedTranscription = '';\n    this.speakerDiarization = '';\n    this.generatedNote = '';\n    this.selectedFileUrl = null;\n    this.isTranscribing = false;\n    // Model Comparison\n    this.comparison = {\n      model1: {\n        type: 'vosk',\n        size: 'small'\n      },\n      model2: {\n        type: 'whisper',\n        size: 'tiny'\n      }\n    };\n  }\n  ngOnInit() {\n    this.loadConfiguration();\n    this.loadTemplates();\n  }\n  ngOnDestroy() {\n    if (this.recordingInterval) {\n      this.recordingInterval.unsubscribe();\n    }\n    if (this.isRecording) {\n      this.stopRecording();\n    }\n    if (this.selectedFileUrl) {\n      URL.revokeObjectURL(this.selectedFileUrl);\n    }\n  }\n  // Configuration Management\n  loadConfiguration() {\n    const savedConfig = localStorage.getItem('medicalTranscriptionConfig');\n    if (savedConfig) {\n      const parsed = JSON.parse(savedConfig);\n      // Force correct model names, ignore old cached values\n      if (parsed.voskModel === 'vosk_small' || parsed.voskModel === 'vosk_large') {\n        parsed.voskModel = 'vosk-model-en-us-0.22';\n      }\n      this.config = {\n        ...this.config,\n        ...parsed\n      };\n    }\n    // Always save the corrected config\n    this.saveConfiguration();\n  }\n  saveConfiguration() {\n    localStorage.setItem('medicalTranscriptionConfig', JSON.stringify(this.config));\n  }\n  resetConfiguration() {\n    // Clear localStorage and reset to defaults\n    localStorage.removeItem('medicalTranscriptionConfig');\n    this.config = {\n      azureApiKey: '',\n      azureEndpoint: 'https://your-resource.openai.azure.com/',\n      noteModel: 'azure',\n      localModel: 'gemma3-4b',\n      asrEngine: 'vosk',\n      voskModel: 'vosk-model-en-us-0.22',\n      whisperModel: 'tiny',\n      encryptRecordings: true,\n      selectedTemplate: 'SOAP'\n    };\n    this.saveConfiguration();\n    alert('Configuration reset to defaults');\n  }\n  onAsrEngineChange() {\n    this.saveConfiguration();\n  }\n  getTemplateDescription() {\n    const selectedTemplate = this.templateOptions.find(t => t.value === this.config.selectedTemplate);\n    return selectedTemplate ? selectedTemplate.description : '';\n  }\n  getLocalModelDescription() {\n    const selectedModel = this.localModelOptions.find(m => m.value === this.config.localModel);\n    return selectedModel ? selectedModel.description : '';\n  }\n  // Template Management Functions\n  loadTemplates() {\n    const savedCustomTemplates = localStorage.getItem('customMedicalTemplates');\n    if (savedCustomTemplates) {\n      this.customTemplates = JSON.parse(savedCustomTemplates);\n    }\n    this.templateOptions = [...this.defaultTemplates, ...this.customTemplates];\n  }\n  saveCustomTemplates() {\n    localStorage.setItem('customMedicalTemplates', JSON.stringify(this.customTemplates));\n    this.templateOptions = [...this.defaultTemplates, ...this.customTemplates];\n  }\n  openTemplateManager() {\n    this.showTemplateManager = true;\n  }\n  closeTemplateManager() {\n    this.showTemplateManager = false;\n    this.selectedTemplateForEditing = null;\n    this.editingTemplateName = '';\n    this.editingTemplatePrompt = '';\n    this.isCreatingNewTemplate = false;\n  }\n  selectTemplateForEditing(template) {\n    this.selectedTemplateForEditing = template;\n    this.editingTemplateName = template.label;\n    this.editingTemplatePrompt = template.prompt;\n    this.isCreatingNewTemplate = false;\n  }\n  startCreatingNewTemplate() {\n    this.isCreatingNewTemplate = true;\n    this.selectedTemplateForEditing = null;\n    this.editingTemplateName = '';\n    this.editingTemplatePrompt = `Please format the following medical transcription into a structured note:\n\n**[TEMPLATE NAME]**\n\n[Add your custom formatting instructions here]\n\nPlease ensure all medical terminology is accurate and properly formatted. Include only information explicitly mentioned in the transcription.`;\n  }\n  saveTemplate() {\n    if (!this.editingTemplateName.trim() || !this.editingTemplatePrompt.trim()) {\n      alert('Please provide both a template name and prompt content.');\n      return;\n    }\n    const templateValue = this.editingTemplateName.toLowerCase().replace(/\\s+/g, '-');\n    if (this.isCreatingNewTemplate) {\n      // Check if template name already exists\n      const exists = this.templateOptions.find(t => t.value === templateValue);\n      if (exists) {\n        alert('A template with this name already exists. Please choose a different name.');\n        return;\n      }\n      // Create new custom template\n      const newTemplate = {\n        value: templateValue,\n        label: this.editingTemplateName.trim(),\n        description: `Custom template: ${this.editingTemplateName.trim()}`,\n        prompt: this.editingTemplatePrompt.trim(),\n        isCustom: true\n      };\n      this.customTemplates.push(newTemplate);\n      this.saveCustomTemplates();\n      // Set as selected template\n      this.config.selectedTemplate = templateValue;\n      this.saveConfiguration();\n      alert('New template created successfully!');\n    } else if (this.selectedTemplateForEditing) {\n      // Update existing template\n      if (this.selectedTemplateForEditing.isCustom) {\n        // Update custom template\n        const customIndex = this.customTemplates.findIndex(t => t.value === this.selectedTemplateForEditing.value);\n        if (customIndex !== -1) {\n          this.customTemplates[customIndex].label = this.editingTemplateName.trim();\n          this.customTemplates[customIndex].prompt = this.editingTemplatePrompt.trim();\n          this.customTemplates[customIndex].description = `Custom template: ${this.editingTemplateName.trim()}`;\n          this.saveCustomTemplates();\n          alert('Template updated successfully!');\n        }\n      } else {\n        // Create new custom version of default template\n        const newCustomTemplate = {\n          value: `${this.selectedTemplateForEditing.value}-custom-${Date.now()}`,\n          label: `${this.editingTemplateName.trim()} (Custom)`,\n          description: `Custom version of ${this.selectedTemplateForEditing.label}`,\n          prompt: this.editingTemplatePrompt.trim(),\n          isCustom: true\n        };\n        this.customTemplates.push(newCustomTemplate);\n        this.saveCustomTemplates();\n        // Set as selected template\n        this.config.selectedTemplate = newCustomTemplate.value;\n        this.saveConfiguration();\n        alert('Custom template created from default template!');\n      }\n    }\n    this.closeTemplateManager();\n  }\n  deleteTemplate(template) {\n    if (!template.isCustom) {\n      alert('Cannot delete default templates. You can only delete custom templates.');\n      return;\n    }\n    if (confirm(`Are you sure you want to delete the template \"${template.label}\"?`)) {\n      this.customTemplates = this.customTemplates.filter(t => t.value !== template.value);\n      this.saveCustomTemplates();\n      // If this was the selected template, switch to default\n      if (this.config.selectedTemplate === template.value) {\n        this.config.selectedTemplate = 'SOAP';\n        this.saveConfiguration();\n      }\n      // Close manager if this template was being edited\n      if (this.selectedTemplateForEditing?.value === template.value) {\n        this.closeTemplateManager();\n      }\n      alert('Template deleted successfully!');\n    }\n  }\n  getCurrentTemplatePrompt() {\n    const currentTemplate = this.templateOptions.find(t => t.value === this.config.selectedTemplate);\n    return currentTemplate ? currentTemplate.prompt : '';\n  }\n  // UI Navigation\n  switchTab(tabName) {\n    this.activeTab = tabName;\n  }\n  toggleSidebar() {\n    this.sidebarCollapsed = !this.sidebarCollapsed;\n  }\n  // Consent Management\n  documentConsent() {\n    if (!this.patientName.trim()) {\n      alert('Please enter patient name');\n      return;\n    }\n    this.consentDocumented = true;\n    this.consentDate = new Date();\n  }\n  // Recording Functions\n  startRecording() {\n    var _this = this;\n    return _asyncToGenerator(function* () {\n      try {\n        // Clear previous transcription text and results\n        _this.finalTranscriptionText = '';\n        _this.partialTranscriptionText = '';\n        _this.lowConfidenceWords = [];\n        _this.rawTranscription = '';\n        _this.cleanedTranscription = '';\n        _this.generatedNote = '';\n        _this.showResults = false;\n        const stream = yield navigator.mediaDevices.getUserMedia({\n          audio: true\n        });\n        _this.mediaRecorder = new MediaRecorder(stream);\n        _this.audioChunks = [];\n        _this.mediaRecorder.ondataavailable = event => {\n          _this.audioChunks.push(event.data);\n        };\n        _this.mediaRecorder.onstop = () => {\n          // In 'traditional' mode, process the full audio blob.\n          // In 'realtime' mode, the transcription is already finalized, so just trigger post-processing.\n          if (_this.recordingMode === 'traditional') {\n            const audioBlob = new Blob(_this.audioChunks, {\n              type: 'audio/wav'\n            });\n            _this.processRecording(audioBlob);\n          } else {\n            _this.rawTranscription = _this.finalTranscriptionText.trim();\n            if (_this.rawTranscription) {\n              _this.updateProgress(2);\n              _this.showResults = true; // Show results immediately after transcription\n              _this.switchTab('record'); // Ensure user is on the record tab to see results\n              _this.cleanTranscription().then(() => {\n                _this.generateSpeakerDiarization();\n                _this.updateProgress(3);\n                _this.generateMedicalNote().then(() => {\n                  _this.updateProgress(4);\n                }).catch(noteError => {\n                  console.error('Error generating note in realtime mode:', noteError);\n                  _this.generatedNote = 'Error generating note. Please check your Azure API configuration.';\n                  _this.updateProgress(4);\n                });\n              }).catch(cleanError => {\n                console.error('Error cleaning transcription in realtime mode:', cleanError);\n                _this.cleanedTranscription = _this.rawTranscription;\n                _this.generateSpeakerDiarization();\n                _this.updateProgress(3);\n              });\n            } else {\n              _this.rawTranscription = 'No transcription available from real-time session.';\n              _this.showResults = true;\n              _this.switchTab('record'); // Ensure user sees the message\n            }\n          }\n        };\n        _this.mediaRecorder.start();\n        _this.isRecording = true;\n        _this.recordingStartTime = Date.now();\n        _this.startRecordingTimer();\n        if (_this.recordingMode === 'realtime') {\n          // Pass the already-acquired stream to avoid a second permission prompt\n          _this.startRealtimeTranscription(stream);\n        }\n        _this.updateProgress(0);\n      } catch (error) {\n        console.error('Error starting recording:', error);\n        alert('Error accessing microphone. Please check permissions.');\n      }\n    })();\n  }\n  pauseRecording() {\n    if (this.mediaRecorder && this.isRecording) {\n      this.mediaRecorder.pause();\n    }\n  }\n  stopRecording() {\n    if (this.mediaRecorder && this.isRecording) {\n      this.mediaRecorder.stop();\n      this.mediaRecorder.stream.getTracks().forEach(track => track.stop());\n      this.isRecording = false;\n      this.stopRecordingTimer();\n      // Handle real-time transcription completion\n      if (this.recordingMode === 'realtime' && this.finalTranscriptionText) {\n        // Transfer real-time transcription to main transcription and process it\n        this.rawTranscription = this.finalTranscriptionText;\n        this.showResults = true;\n        this.switchTab('record'); // Switch back to main view\n        this.showTranscriptionComplete();\n        // Start with step 1 (Transcribe) since recording is done\n        this.updateProgress(1);\n        // Process the real-time transcription through the full pipeline\n        this.processRealtimeTranscription();\n      } else {\n        // For traditional recording, set to step 1 (Transcribe)\n        this.updateProgress(1);\n      }\n      // Cleanup realtime stream\n      if (this.realtimeSocket) {\n        this.realtimeSocket.close();\n        this.realtimeSocket = undefined;\n      }\n      if (this.scriptNode) {\n        this.scriptNode.disconnect();\n        this.scriptNode = undefined;\n      }\n      if (this.audioContext) {\n        this.audioContext.close();\n        this.audioContext = undefined;\n      }\n    }\n  }\n  startRecordingTimer() {\n    this.recordingInterval = interval(1000).subscribe(() => {\n      const elapsed = Math.floor((Date.now() - this.recordingStartTime) / 1000);\n      const minutes = Math.floor(elapsed / 60).toString().padStart(2, '0');\n      const seconds = (elapsed % 60).toString().padStart(2, '0');\n      this.recordingTime = `${minutes}:${seconds}`;\n    });\n  }\n  stopRecordingTimer() {\n    if (this.recordingInterval) {\n      this.recordingInterval.unsubscribe();\n    }\n  }\n  startRealtimeTranscription(stream) {\n    const SAMPLE_RATE = 16000;\n    // Use the actual model folder name for WebSocket\n    const modelParam = this.config.voskModel || 'vosk-model-en-us-0.22';\n    const wsUrl = `ws://${location.hostname}:8000/ws/vosk?model=${encodeURIComponent(modelParam)}`;\n    console.log('Connecting to WebSocket:', wsUrl);\n    this.realtimeSocket = new WebSocket(wsUrl);\n    this.realtimeSocket.onopen = () => {\n      console.log('WebSocket connected successfully');\n    };\n    this.realtimeSocket.onerror = error => {\n      console.error('WebSocket error:', error);\n      alert('WebSocket connection failed. Ensure the backend is running and accessible.');\n    };\n    this.realtimeSocket.onclose = event => {\n      console.log('WebSocket closed:', event.code, event.reason);\n      // If closed unexpectedly, clean up audio resources to prevent errors\n      if (this.scriptNode) {\n        this.scriptNode.disconnect();\n      }\n      if (this.audioContext && this.audioContext.state !== 'closed') {\n        this.audioContext.close();\n      }\n    };\n    this.realtimeSocket.onmessage = ({\n      data\n    }) => {\n      const msg = JSON.parse(data);\n      console.log('WebSocket message received:', msg);\n      if (msg.type === 'partial') {\n        this.partialTranscriptionText = msg.text;\n      }\n      if (msg.type === 'final') {\n        if (msg.text) {\n          this.finalTranscriptionText += (this.finalTranscriptionText ? ' ' : '') + msg.text;\n          console.log('Final transcription updated:', this.finalTranscriptionText);\n          // Check for low confidence words if result contains word details\n          if (msg.result && msg.result.length > 0) {\n            const lowConfWords = msg.result.filter(word => word.conf && word.conf < 0.8).map(word => word.word);\n            if (lowConfWords.length > 0) {\n              this.lowConfidenceWords = [...new Set([...this.lowConfidenceWords, ...lowConfWords])];\n            }\n          }\n        }\n        this.partialTranscriptionText = '';\n      }\n    };\n    // Use the stream passed from startRecording() to avoid a second permission prompt\n    try {\n      this.audioContext = new (window.AudioContext || window.webkitAudioContext)({\n        sampleRate: SAMPLE_RATE\n      });\n      const source = this.audioContext.createMediaStreamSource(stream);\n      // Deprecated but widely supported – adequate for demo purposes\n      this.scriptNode = this.audioContext.createScriptProcessor(4096, 1, 1);\n      this.scriptNode.onaudioprocess = event => {\n        // Don't process audio if recording has stopped or WebSocket is not open\n        if (!this.isRecording || !this.realtimeSocket || this.realtimeSocket.readyState !== WebSocket.OPEN) {\n          return;\n        }\n        const input = event.inputBuffer.getChannelData(0);\n        const buffer = new ArrayBuffer(input.length * 2);\n        const view = new DataView(buffer);\n        for (let i = 0; i < input.length; i++) {\n          const s = Math.max(-1, Math.min(1, input[i]));\n          view.setInt16(i * 2, s < 0 ? s * 0x8000 : s * 0x7FFF, true);\n        }\n        this.realtimeSocket.send(buffer);\n      };\n      source.connect(this.scriptNode);\n      // We connect the script node to the destination to avoid audio being silenced in some browsers.\n      this.scriptNode.connect(this.audioContext.destination);\n    } catch (err) {\n      console.error('Error setting up AudioContext for real-time transcription:', err);\n      alert('Failed to set up real-time audio processing.');\n    }\n  }\n  processRecording(audioBlob) {\n    var _this2 = this;\n    return _asyncToGenerator(function* () {\n      const audioFile = new File([audioBlob], 'recording.' + (audioBlob.type.split('/')[1] || 'webm'), {\n        type: audioBlob.type\n      });\n      try {\n        _this2.updateProgress(1);\n        const response = yield _this2.transcriptionService.transcribeAudio(audioFile, _this2.getSelectedModel(), 'en-US', _this2.getVoskModelPath()).toPromise();\n        if (response) {\n          _this2.rawTranscription = response.transcript;\n          _this2.updateProgress(2);\n          _this2.showResults = true; // Show results immediately after transcription\n          _this2.switchTab('record'); // Ensure user is on the record tab to see results\n          _this2.showTranscriptionComplete();\n          // Clean transcription\n          try {\n            yield _this2.cleanTranscription();\n            _this2.updateProgress(3);\n          } catch (cleanError) {\n            console.error('Error cleaning transcription:', cleanError);\n            _this2.cleanedTranscription = _this2.rawTranscription; // Fallback to raw transcription\n            _this2.updateProgress(3);\n          }\n          // Generate speaker diarization (simulate for now)\n          _this2.generateSpeakerDiarization();\n          // Generate note\n          try {\n            yield _this2.generateMedicalNote();\n            _this2.updateProgress(4);\n          } catch (noteError) {\n            console.error('Error generating note:', noteError);\n            _this2.generatedNote = 'Error generating note. Please check your Azure API configuration.';\n            _this2.updateProgress(4);\n          }\n        } else {\n          // Even if no response, show some feedback\n          _this2.rawTranscription = 'No transcription result received.';\n          _this2.showResults = true;\n          _this2.switchTab('record'); // Ensure user sees the error message\n        }\n      } catch (error) {\n        console.error('Error processing recording:', error);\n        // Show results even on error so user can see what happened\n        _this2.rawTranscription = `Error: ${error?.error?.error || error.message || 'Unknown transcription error'}`;\n        _this2.showResults = true;\n        _this2.updateProgress(2);\n        _this2.switchTab('record'); // Ensure user sees the error message\n      }\n    })();\n  }\n  getSelectedModel() {\n    if (this.config.asrEngine === 'vosk') {\n      return 'vosk';\n    } else if (this.config.asrEngine === 'whisper') {\n      return `whisper_${this.config.whisperModel}`;\n    }\n    return 'vosk';\n  }\n  getVoskModelPath() {\n    if (this.config.asrEngine === 'vosk') {\n      return `app_data/models/${this.config.voskModel}`;\n    }\n    return undefined;\n  }\n  cleanTranscription() {\n    var _this3 = this;\n    return _asyncToGenerator(function* () {\n      // Simulate transcription cleaning\n      _this3.cleanedTranscription = _this3.rawTranscription.replace(/um/g, '').replace(/uh/g, '').replace(/\\s+/g, ' ').trim();\n    })();\n  }\n  generateSpeakerDiarization() {\n    // Generate a simple speaker diarization based on the transcription\n    if (this.rawTranscription && this.rawTranscription.trim()) {\n      // Simple simulation - split by sentences and alternate speakers\n      const sentences = this.rawTranscription.split(/[.!?]+/).filter(s => s.trim());\n      let diarization = '';\n      sentences.forEach((sentence, index) => {\n        if (sentence.trim()) {\n          const speaker = index % 2 === 0 ? 'Doctor' : 'Patient';\n          diarization += `<p><strong>${speaker}:</strong> ${sentence.trim()}.</p>`;\n        }\n      });\n      this.speakerDiarization = diarization || '<p><strong>Doctor:</strong> How are you feeling today?</p><p><strong>Patient:</strong> I\\'ve been experiencing some discomfort...</p>';\n    } else {\n      this.speakerDiarization = '<p><strong>Doctor:</strong> How are you feeling today?</p><p><strong>Patient:</strong> I\\'ve been experiencing some discomfort...</p>';\n    }\n  }\n  generateMedicalNote() {\n    var _this4 = this;\n    return _asyncToGenerator(function* () {\n      try {\n        const noteRequest = {\n          transcript: _this4.rawTranscription,\n          template: _this4.config.selectedTemplate,\n          api_key: _this4.config.azureApiKey,\n          endpoint: _this4.config.azureEndpoint,\n          model: 'gpt-4o',\n          use_local: _this4.config.noteModel === 'local',\n          local_model: _this4.config.localModel\n        };\n        const response = yield _this4.transcriptionService.generateNote(noteRequest).toPromise();\n        if (response) {\n          _this4.generatedNote = response.note;\n        }\n      } catch (error) {\n        console.error('Error generating note:', error);\n        _this4.generatedNote = '<h4>SOAP Note</h4><p><strong>Subjective:</strong> Patient reports...</p><p><strong>Objective:</strong> Vital signs...</p><p><strong>Assessment:</strong> Clinical impression...</p><p><strong>Plan:</strong> Treatment recommendations...</p>';\n      }\n    })();\n  }\n  // File Upload Functions\n  onFileSelected(event) {\n    const file = event.target.files[0];\n    if (file) {\n      this.selectedFile = file;\n      if (this.selectedFileUrl) {\n        URL.revokeObjectURL(this.selectedFileUrl);\n      }\n      this.selectedFileUrl = URL.createObjectURL(file);\n    }\n  }\n  clearSelectedFile() {\n    if (this.selectedFileUrl) {\n      URL.revokeObjectURL(this.selectedFileUrl);\n    }\n    this.selectedFile = undefined;\n    this.selectedFileUrl = null;\n    // Reset any transcription state\n    this.currentStep = 0;\n    this.showResults = false;\n    this.rawTranscription = '';\n    this.cleanedTranscription = '';\n    this.generatedNote = '';\n    this.speakerDiarization = '';\n    console.log('Selected file cleared. You can now choose a different file.');\n  }\n  onDragOver(event) {\n    event.preventDefault();\n    const uploadArea = event.target;\n    uploadArea.style.borderColor = 'var(--primary-color)';\n    uploadArea.style.background = 'rgba(37, 99, 235, 0.05)';\n  }\n  onDragLeave(event) {\n    const uploadArea = event.target;\n    uploadArea.style.borderColor = 'var(--border-color)';\n    uploadArea.style.background = 'transparent';\n  }\n  onDrop(event) {\n    event.preventDefault();\n    const uploadArea = event.target;\n    uploadArea.style.borderColor = 'var(--border-color)';\n    uploadArea.style.background = 'transparent';\n    const files = event.dataTransfer?.files;\n    if (files && files.length > 0) {\n      this.selectedFile = files[0];\n      if (this.selectedFileUrl) {\n        URL.revokeObjectURL(this.selectedFileUrl);\n      }\n      this.selectedFileUrl = URL.createObjectURL(files[0]);\n    }\n  }\n  uploadAndTranscribe() {\n    var _this5 = this;\n    return _asyncToGenerator(function* () {\n      if (!_this5.selectedFile || _this5.isTranscribing) return;\n      try {\n        _this5.isTranscribing = true;\n        _this5.currentStep = 0;\n        _this5.showResults = false;\n        _this5.updateProgress(1);\n        const response = yield _this5.transcriptionService.transcribeAudio(_this5.selectedFile, _this5.getSelectedModel(), 'en-US', _this5.getVoskModelPath()).toPromise();\n        if (response) {\n          _this5.rawTranscription = response.transcript;\n          _this5.updateProgress(2);\n          yield _this5.cleanTranscription();\n          _this5.updateProgress(3);\n          yield _this5.generateMedicalNote();\n          _this5.updateProgress(4);\n          _this5.showResults = true;\n          // Show brief success notification\n          setTimeout(() => {\n            console.log('✅ Transcription and note generation completed successfully!');\n          }, 100);\n        }\n      } catch (error) {\n        console.error('Error uploading file:', error);\n        alert(`Error uploading file: ${error?.error?.error || error.message || 'Unknown error'}`);\n        // Reset progress on error\n        _this5.currentStep = 0;\n        _this5.showResults = false;\n      } finally {\n        _this5.isTranscribing = false;\n      }\n    })();\n  }\n  // Utility Functions\n  updateProgress(step) {\n    this.currentStep = step;\n    // Manually trigger change detection to ensure UI updates immediately\n    this.cdr.detectChanges();\n  }\n  copyToClipboard(text) {\n    if (text) {\n      navigator.clipboard.writeText(text.replace(/<[^>]*>/g, '')).then(() => {\n        // Could show a toast notification here\n        console.log('Copied to clipboard');\n      });\n    }\n  }\n  downloadText(text, filename) {\n    if (text) {\n      const cleanText = text.replace(/<[^>]*>/g, '');\n      const blob = new Blob([cleanText], {\n        type: 'text/plain'\n      });\n      const url = window.URL.createObjectURL(blob);\n      const a = document.createElement('a');\n      a.href = url;\n      a.download = filename;\n      a.click();\n      window.URL.revokeObjectURL(url);\n    }\n  }\n  editNote() {\n    // Could open a modal or navigate to an edit view\n    console.log('Edit note functionality');\n  }\n  exportResults() {\n    const results = {\n      patient: this.patientName,\n      date: this.consentDate,\n      rawTranscription: this.rawTranscription,\n      cleanedTranscription: this.cleanedTranscription,\n      generatedNote: this.generatedNote\n    };\n    const blob = new Blob([JSON.stringify(results, null, 2)], {\n      type: 'application/json'\n    });\n    const url = window.URL.createObjectURL(blob);\n    const a = document.createElement('a');\n    a.href = url;\n    a.download = `medical-transcription-${new Date().toISOString().split('T')[0]}.json`;\n    a.click();\n    window.URL.revokeObjectURL(url);\n  }\n  runComparison() {\n    console.log('Running model comparison:', this.comparison);\n    // Implement model comparison logic\n  }\n  processRealtimeTranscription() {\n    var _this6 = this;\n    return _asyncToGenerator(function* () {\n      // Process real-time transcription through the full pipeline\n      try {\n        console.log('Starting real-time transcription processing pipeline...');\n        // Step 2: Clean transcription (step 1 is transcribe, already done)\n        try {\n          console.log('Cleaning transcription...');\n          yield _this6.cleanTranscription();\n          _this6.updateProgress(2); // Step 3: Clean\n          yield _this6.delay(200); // Small delay to ensure UI updates\n        } catch (cleanError) {\n          console.error('Error cleaning transcription:', cleanError);\n          _this6.cleanedTranscription = _this6.rawTranscription; // Fallback to raw transcription\n          _this6.updateProgress(2);\n          yield _this6.delay(200);\n        }\n        // Generate speaker diarization\n        console.log('Generating speaker diarization...');\n        _this6.generateSpeakerDiarization();\n        // Step 4: Generate note\n        try {\n          console.log('Generating medical note...');\n          yield _this6.generateMedicalNote();\n          _this6.updateProgress(3); // Step 4: Generate Note (0-indexed, so 3 = step 4)\n          console.log('Real-time processing complete!');\n        } catch (noteError) {\n          console.error('Error generating note:', noteError);\n          _this6.generatedNote = 'Error generating note. Please check your configuration.';\n          _this6.updateProgress(3);\n        }\n        // Clear real-time transcription text since it's now processed\n        _this6.finalTranscriptionText = '';\n        _this6.partialTranscriptionText = '';\n      } catch (error) {\n        console.error('Error processing real-time transcription:', error);\n        _this6.updateProgress(4);\n      }\n    })();\n  }\n  delay(ms) {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n  showTranscriptionComplete() {\n    // Add a brief visual indicator that transcription is complete\n    console.log('✅ Transcription completed and results are now visible');\n    // Could add a toast notification here in the future\n  }\n};\nAppComponent = __decorate([Component({\n  selector: 'app-root',\n  templateUrl: './app.component.html',\n  styleUrls: ['./app.component.css']\n})], AppComponent);\nexport { AppComponent };","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}